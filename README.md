# Ollama Chat GUI

A modern chat interface for Ollama LLM models with streaming responses.

## Features

- Real-time streaming of AI responses
- Markdown rendering with proper code highlighting
- Conversation history for continuous interactions
- Responsive design for desktop and mobile
- Support for tables and rich formatting

## Installation

1. Clone the repository
2. Install dependencies:
   ```
   npm install
   ```
3. Make sure Ollama is installed and running on your system
4. Start the server:
   ```
   npm start
   ```

## Usage

1. Open your browser and navigate to `http://localhost:3001/`
2. Type a message and press Enter to chat with the AI
3. Use Shift+Enter for multi-line messages

## Technology Stack

- Frontend: HTML, CSS, JavaScript
- Backend: Node.js, Express
- AI: Ollama with gemma3 model

## License

MIT